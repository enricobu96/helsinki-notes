---
attachments: [Clipboard_2021-09-21-10-17-29.png, Clipboard_2021-09-21-10-18-48.png, Clipboard_2021-09-21-10-19-45.png, Clipboard_2021-09-21-10-21-14.png, Clipboard_2021-09-21-10-21-26.png, Clipboard_2021-09-21-10-23-13.png, Clipboard_2021-09-21-10-44-12.png, Clipboard_2021-09-21-10-51-01.png, Clipboard_2021-09-21-10-55-18.png, Clipboard_2021-09-21-10-59-06.png, Clipboard_2021-09-21-11-03-30.png]
tags: [Big Data Platforms]
title: Lesson 5 - 21/09
created: '2021-09-21T07:16:38.857Z'
modified: '2021-09-21T08:22:41.446Z'
---

# Lesson 5 - 21/09

## Let's start with an excercise

![](@attachment/Clipboard_2021-09-21-10-17-29.png)

-> 16 drives in the array

Solution: since the system is set up in a RAID 0 configuration, the rist error that occurs in any of the disks will break the disk array. We know that the error process for each of the K hdds can be modeled as a Poisson process, where the transition frequency (failing of hdd) of each drive is `lambda`:

![](@attachment/Clipboard_2021-09-21-10-18-48.png)

And so:

![](@attachment/Clipboard_2021-09-21-10-19-45.png)

So 2 years to a failure (in avg): not fault-tolerant at all!

## Another excercise

![](@attachment/Clipboard_2021-09-21-10-21-26.png)

Solution:

![](@attachment/Clipboard_2021-09-21-10-23-13.png)

Still quite high! More than 13% of URE probability

## Storage technologies for the Cloud

Widely used storage technologies in the cloud:

- RAM (Random Access Memory)
- Flash (SSD - Solid State Drive)
- Hard disk
- Tape (slightly cheaper than HDDs on a large scale)

### Flash Storage

- Currently one of the trends is the introduction of Flash Memory SSDs and replacing hard disks in many applications
- Flash capacity per Euro is increasing faster than hard disk capacity per Euro
- Currently Flash Capacity is aroun 10% of all Enterprise sotrage capacity (but it's growing quickly)
- Random SSD read (and often also write) IOPS can be more than 1000 × those of high end hard disk read and write IOPS
- Sequential read and write speeds are much faster
- As SSDs have no moving parts they are fail quite a bit less frequently than hard disks
- As such SSDs are a very good match for typical client laptop and desktop usage patterns

#### Strength and limitations

SSDs have both:
- The write endurance in SSDs is quite often very small compared to HDDs
- For write intensive server workloads HDDs might still be the only economically write endurance is exhausted
- Apart from that, Flash drives have typically less failures than hard drives

#### Flash organization

- A flash chip is organized in pages of some KBs in size (e.g. 2KB)
- A page read can load data of a page into a buffers that can be quicklu randomly accessed
- A page write can only flip bits of the page from 0 to 1
- In order to change the bits from 1 to 0 an erase operation operating a large number of block needs to be performed; works on blocks that consist of several flash pages at the time (e.g. 128KB of data)
- If the blocks to be erased contain some data, that data must be written elsewhere before the block is erased

#### Flash types

- Several "flavours", the main ones being NAND flash in varieties: quad-level cell QLC (cheapest, ~HDDs in speed), triple-level cell TLC, multi-level cell MLC (cheap), sinle-level cell SLC (expensive)
- Flash blocks can be erased: ~1000 times (TLC), 1000~10000 times (MLC), 100000~1000000 times (SLC)

#### Flash wear levelling algorithms

- Highly sophisticated algorithms are used for wear leveling, where the goal is to write each flash cell as evenly as prossible
- When flash disk becomes almost full, the free space can become fragmented (-> performance loss on writes as the SSD moves blocks around to make space for the written data)
- Flash disks often use "spare capacity" set aside to make the fragmentation problem less severe

#### Sustained flash write performance

Because of the RAM write caches and the write leveling algorithms, the sustained Flash memory speeds can sometimes frop for long workloads

![](@attachment/Clipboard_2021-09-21-10-44-12.png)

#### Optimizing for Flash

- One should minimize the number of bytes written to Flash:
  - Less bytes written = less wear = longer lifetime expectancy of Flash
  - Less bytes written = less freqent block erase = more IOPS
- Heavy sequential write workloads (e.g. database logs) can sometimes be problematic due to write endurance limiting the lifetime of the Flash
- Operating systems support such as the TRIM command which tells to the SSD which data blocks can be safely discarded is very useful

#### Rule of Thumb numbers for Flash & storage price trends

For a single raandom access read:
- RAM: 100ns
- Flash drives: 100000ns (100x slower than RAM)
- Disk seek: 10000000 (100000x slower than RAM)

![](@attachment/Clipboard_2021-09-21-10-51-01.png)

#### Enterprise Hard Disk vs Flash prices

![](@attachment/Clipboard_2021-09-21-10-55-18.png)

Currently Enterprise Flash price premium per TB of storage over high capacity HDDs is still significant. For small client drives SSDs are already very price competitive with hard disks

### Storage usage scenarios

- Tapes are still being used for backup purposes as they are cheap per TB
- RAM and Flash are radically faster than HDDs: one should use RAM/Flash whenever possible
- RAM is roughly the sam price as HDDs were 10 years ago:
  - Workloads that where viable with HDDs 10 years ago are now feasible on main memory
  - One should only use hard disk based storage for datasets that are not yet economically viable in RAM (or Flash)
  - The Big Data applications (HDD based massive storage) should consist of applications that were not economically feasible a decade ago using HDDs

### Cost of Storage: RAM vs Flash vs Disk

![](@attachment/Clipboard_2021-09-21-10-59-06.png)

- You can watch at numbers of query rate and dataset size and decide
- Most practical system contain datasets with different "temperatures":
  - Hot storage: when a large number of IOPS/TB is needed, RAM is the cheapest way to obtain lots of IOPS
  - Cold storage: when a large number of TB/IOPS is needed, HDDs are the cheapest way to obtain lots of storage
  - Warm storage: Flash is a compromise between corst per IOPS and cost per TB
- When the pricing of RAM/Flash/HDD changes, the exact optimal seletion of the best technology changes

### Example: Facebook Storage

Facebook has done research on the warmth of their datasets:

![](@attachment/Clipboard_2021-09-21-11-03-30.png)

### Storage technologies frm Jim Gray's view

- Tape is dead
- Disk is tape
- Flash is disk
- Ram locality is King

#### On disks 

- Disks are cheap per capacity
- Sequential access full disk reads of take hours
- Random access full disk reads take weeks
- Thus most of disk should be treated as cold-storage

#### On flash

- Lots of IOPS
- Expensive compared to disks but improving
- Limited write endurance
- Slow to write (compared to read)

#### On RAM

- Flash/disk is 100000~1000000 cycles away from the CPU
- RAM is 100 cycles away from the CPU
- Thus Jim Gray concludes that main memory databases are going to be common

### Caching to improve Hard Disk Performance

- Caching the hot part of the dataset in RAM is a well known technique for improving the performance of a hard disk based storage system
- The large difference in RAM and hard disk random access latencies makes this sometimes difficult, as caches need to have extremely good hit rates for the hard disk accesses not to dominate

### RAMCloud

- Facebook in 2009 has been running with enough RAM to fit 75% of their dataset (excl. images and videos) in RAM
- They would use enough RAM cache to hit 99% of the dataset, the random disk seek latency would still kill their average latency performance: (99% × 100 ns + 1% × 10000000 ns) = 100099 ns, which is way more that 100ns!

#### Discussing the numbers

- With flash disks and 99% cache hit rate we get latencies: (99% × 100 ns + 1% × 100000 ns) = 1099 ns, which is still 10x more than 100ns
- The above concerns only average latency, not throughput, but similar reasoning also applies to aggregate IOPS numbers of RAM, Flash and Disk
- If a system can have enough memory to have 100% of the working set in RAM, instead of Flash/HDDs, way better latency can be obtained, and more IOPS can be served with the same number of servers

#### Limiting factors

- The main problem in RAMCloud style designs to guarantee data persistence in case of power failure + quick recovery in case of server crash/power outage
- New non-volatile memory technologies such as Intel/Micron 3D-Xpoint memories that promise even much faster performance than flash might be able to help realize this
- Second problem: to have low latency networking hw and OS to keep RAM busy

### Improving Disk Based Database Performance

- Sometimes we need to create databases that are much larger than can fit the RAM
- RAM is very expensive, and thus should be utilized as well as possible
- Using a normal cache of hot data in RAM can improve query latency for items that are in the database
- RAM can also be used to improve performance for queries of items not in the database:
  - RAM can hold an index of all the items on hard disk
  - Probabilistic data structures use RAM even more efficiently than normal indexes, e.g. bloom filters
