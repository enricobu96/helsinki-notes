---
attachments: [Clipboard_2022-02-01-16-21-55.png, Clipboard_2022-02-01-16-25-38.png, Clipboard_2022-02-01-16-28-26.png, Clipboard_2022-02-01-16-31-17.png, Clipboard_2022-02-01-16-32-50.png, Clipboard_2022-02-01-16-33-11.png, Clipboard_2022-02-01-16-36-14.png, Clipboard_2022-02-01-16-36-32.png, Clipboard_2022-02-01-16-38-04.png, Clipboard_2022-02-01-16-39-16.png, Clipboard_2022-02-01-16-51-39.png, Clipboard_2022-02-01-16-55-17.png, Clipboard_2022-02-01-17-04-36.png, Clipboard_2022-02-01-17-05-01.png, Clipboard_2022-02-01-17-08-00.png, Clipboard_2022-02-01-17-11-46.png, Clipboard_2022-02-01-17-12-23.png, Clipboard_2022-02-01-17-12-50.png, Clipboard_2022-02-01-17-20-43.png, Clipboard_2022-02-01-17-42-37.png, Clipboard_2022-02-01-17-42-49.png, Clipboard_2022-02-01-17-53-57.png, Clipboard_2022-02-01-17-54-14.png]
tags: [Probabilistic Graphical Models]
title: Lesson 5 - 01/02
created: '2022-02-01T14:16:05.321Z'
modified: '2022-02-01T15:54:41.015Z'
---

# Lesson 5 - 01/02

## Graphoid axioms

![](@attachment/Clipboard_2022-02-01-16-21-55.png)

## Factorizing a distribution

How to represent conditional probability distribution? It can be represented as a table (**conditional probability table**), as we saw: ![](@attachment/Clipboard_2022-02-01-16-25-38.png)

![](@attachment/Clipboard_2022-02-01-16-28-26.png)

How to represent the factorizations graphically?
![](@attachment/Clipboard_2022-02-01-16-31-17.png)

This is a DAG!

## Bayesian Networks

![](@attachment/Clipboard_2022-02-01-16-32-50.png)

![](@attachment/Clipboard_2022-02-01-16-33-11.png)

e.g.
![](@attachment/Clipboard_2022-02-01-16-36-32.png)

**As a generative model**
A causal order (topological order) for a BN is any order of variables such that no arcs in G are from a latter node to an earlier node.
![](@attachment/Clipboard_2022-02-01-16-38-04.png)

### Causality?

![](@attachment/Clipboard_2022-02-01-16-39-16.png)

### Local Markov property

![](@attachment/Clipboard_2022-02-01-16-51-39.png)

## d separation

Independencies implied by a Bayesian Network?
![](@attachment/Clipboard_2022-02-01-16-55-17.png)

### Direct connections

![](@attachment/Clipboard_2022-02-01-17-04-36.png)

1. **Chain**: ![](@attachment/Clipboard_2022-02-01-17-05-01.png)
2. **Confounder**: ![](@attachment/Clipboard_2022-02-01-17-08-00.png)
3. **Collider or Selection Bias**: ![](@attachment/Clipboard_2022-02-01-17-11-46.png)
4. **Descendants of a collider**: ![](@attachment/Clipboard_2022-02-01-17-12-23.png)

### d separation

![](@attachment/Clipboard_2022-02-01-17-12-50.png)

### Soundness and Completeness

![](@attachment/Clipboard_2022-02-01-17-20-43.png)

![](@attachment/Clipboard_2022-02-01-17-42-37.png)

![](@attachment/Clipboard_2022-02-01-17-42-49.png)

## Markov equivalence

![](@attachment/Clipboard_2022-02-01-17-53-57.png)

## Markov blanket

![](@attachment/Clipboard_2022-02-01-17-54-14.png)
