---
attachments: [Clipboard_2022-02-02-12-21-13.png, Clipboard_2022-02-02-12-30-37.png, Clipboard_2022-02-02-12-31-01.png, Clipboard_2022-02-02-12-31-45.png, Clipboard_2022-02-02-12-34-20.png, Clipboard_2022-02-02-12-34-41.png, Clipboard_2022-02-02-12-47-57.png, Clipboard_2022-02-02-12-54-24.png, Clipboard_2022-02-02-12-54-43.png, Clipboard_2022-02-02-13-01-32.png, Clipboard_2022-02-02-13-01-46.png, Clipboard_2022-02-02-13-02-00.png, Clipboard_2022-02-02-13-09-54.png, Clipboard_2022-02-02-13-10-13.png, Clipboard_2022-02-02-13-12-30.png, Clipboard_2022-02-02-13-12-46.png, Clipboard_2022-02-02-13-12-56.png, Clipboard_2022-02-02-13-17-23.png, Clipboard_2022-02-02-13-17-28.png, Clipboard_2022-02-02-13-18-17.png]
tags: [Information Retrieval]
title: Lesson 5 - 02/02
created: '2022-02-02T10:10:28.354Z'
modified: '2022-02-02T11:22:39.875Z'
---

# Lesson 5 - 02/02

![](@attachment/Clipboard_2022-02-02-12-21-13.png)

**Information retrieval vs Information extraction**:
- Information Retrieval: given a set of terms and a set of document terms, select only the most relevant document (precision), and preferably all the relevant ones (recall). Finds document but does not need to "understand" them
- Information Extraction: extract from the text what the document means, e.g. text summarization

**vs Web Search**: IR does not necessary happen on the web

## Can we improve recall in search?

Two ways:
- Query expansion/reformulation
- Relevance feedback

### Query expansion/reformulation

![](@attachment/Clipboard_2022-02-02-12-30-37.png)

#### Term re-weighting without query expansion

![](@attachment/Clipboard_2022-02-02-12-31-01.png)

![](@attachment/Clipboard_2022-02-02-12-31-45.png)

#### Query reformulation

Three approaches:

- Relevance feedback: based on feedback from users
- Local analysis (pseudo-relevance feedback): approaches based on information derived from the set of initially retrieved documents
- Global analysis: approaches based on global information derived from the document collection

### Relevance feedback

![](@attachment/Clipboard_2022-02-02-12-34-20.png)

![](@attachment/Clipboard_2022-02-02-12-34-41.png)

Key concept: **centroid**

![](@attachment/Clipboard_2022-02-02-12-47-57.png)

**Rocchio algorithm**
![](@attachment/Clipboard_2022-02-02-12-54-24.png)
![](@attachment/Clipboard_2022-02-02-12-54-43.png)

**Ide**
![](@attachment/Clipboard_2022-02-02-13-01-32.png)

Methods:
![](@attachment/Clipboard_2022-02-02-13-01-46.png)
Eye gaze: ![](@attachment/Clipboard_2022-02-02-13-02-00.png)

### Local analysis

- Examine documents retrieved for query to determine query expansion with no user assistance
- Two strategies are used to add terms to the query:
  - Local clustering (terms that are synonyms, stemming variations)
  - Local context analysis (terms close to query terms in text)

- Two issues:
  - Query drift: if top documents are not that relevant, the reformulated query may not reflect the user information need
  - Computation cost high since must be done at retrieval time (on-line)

![](@attachment/Clipboard_2022-02-02-13-09-54.png)

### Global Analysis

![](@attachment/Clipboard_2022-02-02-13-10-13.png)

![](@attachment/Clipboard_2022-02-02-13-12-30.png)

### Dictionary-based query expansion

![](@attachment/Clipboard_2022-02-02-13-12-46.png)

![](@attachment/Clipboard_2022-02-02-13-12-56.png)

### Authomatic thesaurus generation

![](@attachment/Clipboard_2022-02-02-13-17-23.png)

![](@attachment/Clipboard_2022-02-02-13-17-28.png)

![](@attachment/Clipboard_2022-02-02-13-18-17.png)
