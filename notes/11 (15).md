---
attachments: [Clipboard_2021-11-17-10-20-53.png, Clipboard_2021-11-17-10-21-04.png, Clipboard_2021-11-17-10-21-46.png, Clipboard_2021-11-17-10-21-59.png, Clipboard_2021-11-17-10-25-17.png, Clipboard_2021-11-17-10-34-39.png, Clipboard_2021-11-17-10-35-28.png, Clipboard_2021-11-17-10-36-54.png, Clipboard_2021-11-17-10-37-03.png, Clipboard_2021-11-17-10-37-27.png, Clipboard_2021-11-17-10-37-52.png, Clipboard_2021-11-17-10-38-42.png, Clipboard_2021-11-17-10-40-27.png, Clipboard_2021-11-17-10-40-44.png, Clipboard_2021-11-17-10-41-45.png, Clipboard_2021-11-17-10-42-18.png, Clipboard_2021-11-17-10-42-57.png, Clipboard_2021-11-17-10-47-57.png, Clipboard_2021-11-17-11-51-57.png, Clipboard_2021-11-17-11-52-08.png]
tags: [Human Computer Interaction]
title: Lesson 5 - 17/11
created: '2021-11-17T08:13:39.443Z'
modified: '2021-11-17T09:57:03.083Z'
---

# Lesson 5 - 17/11

## Evaluation (of prototypes)

### Goal of evaluation

Can your prototype support that?
- Depends on the stage of the design process: the evaluation formality will increase with prototype fidelity
- Feedback on early design conepts
- Compare prototypes
- Usability problems
- Legal requirements (does the design validate to an ISO standard?)

### Validity and reliability of a method

![](@attachment/Clipboard_2021-11-17-10-21-46.png)

#### Triangulation and redundancy

![](@attachment/Clipboard_2021-11-17-10-21-59.png)

### Validity

- **Internal validity**: are we measuring what we think we are measuring? Was the evaluation done "right"?
- **External validity**: how generalizable the results are?
- **Ecological validity**: are the results applicable to real world?

### Evaluation methods

![](@attachment/Clipboard_2021-11-17-10-25-17.png)

#### Lab-based evaluation

Typically conducted in a lab.
- Pros: easier to organize time, place and devices for the experiment; enables controlled environment, some variables can be controlled more
- Cons: the actual context may be lost and new unknown variables may rise; question of ercological validity

#### Evaluations in the field

Conducting evaluations in the natural settings, observing and interviewing people.

#### Expert evaluations

Aka evaluations that does not involve end users. An expert walks through the prototype and identifies issues; this can be informal or very formal.
This is not a substitute for involving end users.

##### Cognitive walkthrough

Aka going through a task, with a view of imitating the user and trying to identify problems that the user would face.
1. Develop a persona
2. Develop a scenario about the task: user's motivation, goal, background knowledge, contextual factors
3. Specify what is the correct interaction path to reach the goal
4. Walk through the path and analyse where the user could deviate from the path, not find the next step, etc...

##### Heuristic evaluation

- Done by experts individually and then combined
- Typically produces a large amount of small issues: prioritization of issues is important to find the critical ones
- At early stage of evaluation

![](@attachment/Clipboard_2021-11-17-10-34-39.png)

![](@attachment/Clipboard_2021-11-17-10-35-28.png)

1. Visibility of system status: what the computer is doing (feedback), e.g. ![](@attachment/Clipboard_2021-11-17-10-37-03.png)
2. Match between system and real world: things that match the real world, e.g. ![](@attachment/Clipboard_2021-11-17-10-36-54.png)
3. User control and freedom: to undo things and to do changes in general, e.g. ![](@attachment/Clipboard_2021-11-17-10-37-27.png)
4. Consistency and standards, the interface has to be coherent, e.g. ![](@attachment/Clipboard_2021-11-17-10-37-52.png)
5. Help users recognize, diagnose, and recover from errors, e.g. (the best is on the left because it gives the option to recover from the error) ![](@attachment/Clipboard_2021-11-17-10-38-42.png)
6. Error prevention: users makes errors, prevent them, e.g. ![](@attachment/Clipboard_2021-11-17-10-40-27.png)
7. Recognition rather than recall, e.g. ![](@attachment/Clipboard_2021-11-17-10-40-44.png)
8. Flexibility and efficiency of use: the user should be able to do different things in different order on the same system, e.g. (can find directions for car, bike, bus...) ![](@attachment/Clipboard_2021-11-17-10-41-45.png)
9. Aesthetic and minimalist design, e.g. ![](@attachment/Clipboard_2021-11-17-10-42-18.png)
10. Help and documentation: it should be possible to find help in every place where the user is, e.g. ![](@attachment/Clipboard_2021-11-17-10-42-57.png)

###### Timeanddate.com IMO

- Visibility of system status: not applicable
- Match between system and real world: somewhat respected, like the lunar eclipse image, but overall not present
- User control and freedom: 
- Consitency and standards: more or less yes
- Help users recognize, diagnose and recover from errors: no ![](@attachment/Clipboard_2021-11-17-10-47-57.png) but also yes (home link on the logo) but also no (not all clickable, only the name)
- **Error prevention**: no, for example dropdown menus disappears when the mouse go over for just a fraction of a second, it would be better to have more time leniency
Recognition rather than recall: boh
- **Flexibility and efficiency of use**: flexibility yes, efficiency is somewhat stopped by the cluttered interface
- **Aesthetic and minimalist design**: no, it's full of information on a single page, the design is cluttered and overall is not aesthetically good
- Help and documentation: no; there's a sitemap but it's confusionary

**In group**
There's no minimalist design; dropdown menu
Any help; the sitemap is cluttered and full of information
Different sytles inside the site
Too much functionalities
Email and password

### Evaluations with users

#### Ethics

- Parts of being professional
- Also ofthen procedure: experiments often require advance application for ethics permission
- At very least, develop an informed consent form
- Participants have a right to know the goals o the study, what will happen to the findings, have privacy of personal information

#### Cognitive walkthrough with users

- Going through sample tasks and noting problematic usability issues
- Hierarchical Task Analysis may be used in identifying what subtasks are problematic
  - Does the user understand that this subtask is needed to reach user's goal?
  - Will the user notice that the correct action is available?
  - Will the user understand that the wanted subtask can be achieved by the action
  - Does the user get feedback?
  First three is Gulf of exection, last one is Gulf of evaluation

#### Think-a-loud method

1. Give participant a task
2. Participant performs the task while speaking what they do
3. Encourage participant to keep talking

-> Voice and screen recording

Experimenter: remember to prompt if needed
Participant: remember to describe your throught process

Questions:
- Who played "The doctor" in the 1996 Doctor Who Movie?
- What is the first Star Wars movie?
- What is the highest rated Indiana Jones movie on IMDb?

#### Cooperative evaluation

A novice user going through a task using the interface.

#### Co-discovery

- Used for capturing first impressions in pairs
- Individuals interacting with the technology
- Free exploration or evaluator may ask questions

#### A/B testing

For comparing two different implementations; the winner can be challenged with a better design.
Typically used at a later stage of design process.

#### Controlled experiments

Studies conducted in controlled environments with independent and dependent variables.

### Formative and summative evaluation

**Formative**:
- Aims for improving the system in a constructing way
- Basically all the presented methods

**Summative**:
- Aims for evaluating overall user experience with the system by comparing it against some standard benchmark
- e.g. how likely would you recommend our company/product/service to a friend or a collegue?

### Short-term and longitudinal evaluation

Longitudinal studies are typically observational: no comparison between conditions.
Common longitudinal techniques are quantitative:
- Experience sampling
- Questionnaires
- Data logs

## How to choose evaluation approach and methods

The evaluation approach influences the methods used and, in turn, how data is gathered, analysed and presented.
