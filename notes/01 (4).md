---
attachments: [Clipboard_2022-01-20-14-48-44.png, Clipboard_2022-01-20-14-48-55.png, Clipboard_2022-01-20-14-55-06.png, Clipboard_2022-01-20-14-56-12.png, Clipboard_2022-01-20-14-57-53.png, Clipboard_2022-01-20-15-09-20.png, Clipboard_2022-01-20-15-14-58.png, Clipboard_2022-01-20-15-16-37.png, Clipboard_2022-01-20-15-17-03.png, Clipboard_2022-01-20-15-18-14.png, Clipboard_2022-01-20-15-18-42.png, Clipboard_2022-01-20-15-20-25.png, Clipboard_2022-01-20-15-58-18.png, Clipboard_2022-01-20-15-58-30.png, Clipboard_2022-01-20-16-05-48.png, Clipboard_2022-01-20-16-06-16.png, Clipboard_2022-01-20-16-11-10.png, Clipboard_2022-01-20-18-58-24.png, Clipboard_2022-01-20-18-59-13.png, Clipboard_2022-01-20-18-59-31.png]
tags: [Information Retrieval]
title: Lesson 2 - 19/01
created: '2022-01-20T12:43:33.977Z'
modified: '2022-01-20T17:01:05.357Z'
---

# Lesson 2 - 19/01

## Data compression

- The aim is to take some data that uses x bits and to make it use less bits
- If we can get back to the original representation from the compressed one, we say the compression is **lossless**

Why?
- Less disk space
- Increase speed (more stuff in memory)
- Increase speet of transferring data from disk to memory

TMYK: decompression algorithms are fast

### Recap on inverted indexes

![](@attachment/Clipboard_2022-01-20-14-48-44.png)

![](@attachment/Clipboard_2022-01-20-14-48-55.png)

### Why does Google use compression?

- We can compress both components of an inverted index
- Today the lists are much bigger than lexicon (at least factor 10) -> if we don't compress them we'll have to store them on disk because they're enormous. Compression allows to keep (most of) them in memory

### Baselines

We could just store each inverted list as an array of unsigned integers:
- No compression
- 32 bits = 4B for each doc id
- Allows for collections up to N = ~4bln docs

We a little more effort we could use log2(N) bits:
- Each doc id is in the range 0..N-1, so log2(N) bits is enough
- No compression but could be smaller than 32 bits per doc id

### Compressing - Basics

Key idea for compressing inverted lists: observe that elements of L are monotonically increasing -> we can tranform the list by taking differences (gaps)

![](@attachment/Clipboard_2022-01-20-14-55-06.png)

This is:
- Working, because, integers smaller
- Easy to "degap"

Simple conjunctive query with gaps: ![](@attachment/Clipboard_2022-01-20-14-56-12.png)

#### Compressing - Variable Length Encoding

![](@attachment/Clipboard_2022-01-20-14-57-53.png)

In order to do that, we need to devise some form of variable length encoding: use few bits for small gaps, many bits for large gaps.

#### Binary representations

![](@attachment/Clipboard_2022-01-20-15-09-20.png)

Kidding...but minimal condes alone are no good, because we need to be able to decompress as well: our coding scheme must be **self-delimining**, i.e. the code itself must tell us where the code ends

#### Unary codes

First try of self-delimiting code

![](@attachment/Clipboard_2022-01-20-15-14-58.png)

#### Elias Gamma codes

First non-trivial integer code, represent an integer n>0 as a pair of selector and offset:
![](@attachment/Clipboard_2022-01-20-15-16-37.png)

![](@attachment/Clipboard_2022-01-20-15-17-03.png)

Also, there's an optimization: the most significant bit is always 1 -> no needed to store it

##### Decoding a Gamma code

![](@attachment/Clipboard_2022-01-20-15-18-14.png)

##### Length of a Gamma code

![](@attachment/Clipboard_2022-01-20-15-18-42.png)

#### Variable byte (VB) code

Variable-length codes that are sensitive to memory alignment

![](@attachment/Clipboard_2022-01-20-15-20-25.png)

**Encoding algorithm**: ![](@attachment/Clipboard_2022-01-20-15-58-18.png)

**Decoding algorithm**: ![](@attachment/Clipboard_2022-01-20-15-58-30.png)

Why?:
- When decoding we read whole bytes and inspect only the most significant bit of each byte
- Reading bytes is fast for a computer
- Might be bigger then gamma codes, but still offer decent compression AND are much faster to decode

#### Other

![](@attachment/Clipboard_2022-01-20-16-05-48.png)

#### A real-world example: compression of GOV2 collection

![](@attachment/Clipboard_2022-01-20-16-06-16.png)

### Document reordering

#### Digression: clustering in postings lists

- When document ids are clustered inside a postings list (inverted index, ndr) we get small gaps values that vbyte and gamma codes can compress well
- Document ids can become clustered inside postings lists in at least two ways:
  - **Natural**: e.g. when a term is trending; if a term is mentioned on Twitter, it has an increased likelihood to be mentioned again soon -> clustering of doc ids
  - We can try to **induce it** before building index: give documents containing similar words similar ids. A common heuristic is to order the documents by URL; within a domain, docs have similar vocabulary

  ![](@attachment/Clipboard_2022-01-20-16-11-10.png)

#### Elias-Fano representation

![](@attachment/Clipboard_2022-01-20-18-58-24.png)

![](@attachment/Clipboard_2022-01-20-18-59-13.png)

![](@attachment/Clipboard_2022-01-20-18-59-31.png)

##### Access

To get the lower part we can simply jump to the corresponding bits since we know the length stored for each element. To compute the higher part we need to perform a select_1(i) - i, where select_1(i) is defined as the operation which returns the position of the i-th set-bit and there are techniques to perform it in nearly constant time.

##### NextGEQ

Another interesting operation is NextGEQ(x), which returns the next integer of the sequence that is greater or equal than x. We retrieve the position p by performing select_0(hx) âˆ’ hx where hx is the bucket in which x belongs to. At this point, we start to scan the elements from position p and we stop at the first one greater than x. The scan can traverse at most the size of the bucket.
