---
attachments: [Clipboard_2021-10-12-10-22-52.png, Clipboard_2021-10-12-10-28-18.png, Clipboard_2021-10-12-10-33-50.png, Clipboard_2021-10-12-10-59-47.png, Clipboard_2021-10-12-10-59-56.png, Clipboard_2021-10-12-11-00-07.png, Clipboard_2021-10-12-11-01-37.png, Clipboard_2021-10-12-11-02-31.png]
tags: [Big Data Platforms]
title: Lesson 9 - 12/10
created: '2021-10-12T07:13:41.593Z'
modified: '2021-10-12T08:16:25.181Z'
---

# Lesson 9 - 12/10

## Amazon Dynamo

- The "mother of all eventually consistent datastores". aims to be always writable
- Is an Available and Partition tolerant (AP) design
- A key-value store, binary large object (BLOB) data can be looked up by a primary key
- Based on a distributed hash table (DHT), used also by many peer-to-peer systems for data distribution and lookup
- Uses consistent hashing to enable easy elasticity to add or remove servers from a datastore system based on load
- Conflictiong data versions are resolved at data read time
- Uses vector clocks for automatically resolving some of the conflicts caused by network partitions
- (Handled the Amazon shopping cart system)

### Consistent hashing

- A way to ditribute the contents of a hash table over a distributed hash table (DHT)
- Main advantage: elasticity. Namely if hash table contains `K` keys, and is distributed over `n` servers, either adding or removing a server will online require the relocation of `O(K/n)` keys; they need to be moved for any hashing scheme that maintains an even load balance (thus the method is basically optimal)
- Basic idea: assume the key space is 128 bits (use e.g. SHA-1)
- Each compute node selects a random unique node identifier $n_i$ between 0 and $2^{128} - 1$

![](@attachment/Clipboard_2021-10-12-10-22-52.png)

- All computer nodes are totally clockwise ordered to a virtual ring of servers in increasing node identifier order

![](@attachment/Clipboard_2021-10-12-10-28-18.png)

#### Implementation detail

- Dynamo distributes the node id information to all nodes to achieve O(1) lookup of the correct node the data is stored on
- In order to do 3-way replication, Dynamo stores a copy of the data in the node itself and in its two successors clockwise in the ring
- In order to better balance the load (storage requirements), each node of the network simulates 10+ “virtual nodes”, each with their own id. In addition to load balancing, this helps with performance when nodes are added or removed from the system
- Careful with virtual nodes and replication: replicating data on three virtual nodes in the same physical node gives no hardware redundancy. Dynamo handles this problem

![](@attachment/Clipboard_2021-10-12-10-33-50.png)

### Data versioning

- In order to implement the eventual consistency model, Dynamo has the notion of data versioning: Each data item stored in Dynamo has a version number
- During network partition a Dynamo data put() method will return before all replicas are updated with the data value
- A technique called hinted handoff is used to store data items destined for nodes that are unreachable due to network partition
- This allows writes to proceed on both sides of a network partition
- When network connectivity returns, data versioning can often be used to recover which versions of the data items are obsolete and which versions are the most current ones

### Vector clocks

- Dynamo allows several versions of the data to exists at the same time in the datastore
- Uses vector clocks to track the modifications made by servers to data items
  - One vector clock is a list of [server, clock]-pairs, where clock is a monotonically increasing update counter for server
  - The vector clock basically lists the versions from which the data item to be put() has been derived from
- On read: If Dynamo finds multiple versions of the same data, it will return all the most recent ones to the application
- If multiple versions are returned, the client must merge them to reconcile the conflicting versions

![](@attachment/Clipboard_2021-10-12-10-59-47.png)

![](@attachment/Clipboard_2021-10-12-10-59-56.png)

![](@attachment/Clipboard_2021-10-12-11-00-07.png)

### Conflict and merge routines

- Vector clocks are expensive to implement, and thus also other cheaper mechanisms (allowing less automated merging) are used in practice
- AP systems allowing concurrent writes will eventually have conflicts that can not be automatically merged
- What happens if the application has not provided a merge routine?
- Many databases default to “Last Write Wins (LWW)”- using real time timestamp to figure out which update was the most recent chronologically
- LWW can result in data loss! It throws away one of the conflicting versions instead of merging its contents
- Be careful when using AP datastores and check how they perform merges

### Read and write quorums

![](@attachment/Clipboard_2021-10-12-11-01-37.png)

### Other features

- Hinted handoff: If a replica is not available for writes, an arbitrary node can take its place and store data for it until the replica in question comes available
- A hierarchical hashing algorithm called Merkle trees is used to update data to a replica node that has been offline for a while and comes back to join the ring
- A gossip based protocol is used to find failed nodes in the ring and to eventually replace them
- Local storage engine based on MySQL

### Advanced techniques

![](@attachment/Clipboard_2021-10-12-11-02-31.png)

## Apache Cassandra

- Apache Cassandra is a cloud datastore that values low latency and availability over consistency
- Developed originally by Facebook, now also commercially supported by Datastax
- Runs behind many massive Websites: Example - Netflix
- It uses a BigTable-like data model and a write optimized storage engine based on SSTables
- Apache Cassandra is maybe the closest open source project in spirit to Amazon Dynamo
- Low latency and availability over consistency
- Its design resembles that of Dynamo:
  - Quorum reads and writes with configurable N, W, and R. Also new Paxos based “light transactions” for atomic updates inside a single partition.
  - No vector clocks available! Automatic merging of conflicting versions during reads using “read repair”, where the data item with the largest timestamp value wins!!! (mutating data stored in Cassandra can be dangerous without proper care!)
- ScyllaDB is a Cassandra clone written in C++

## Riak

- Another widely used AP datastore
- Just key-values, not wide rows like in Bigtable or Cassandra
- Uses consistent hashing
- Last write wins (LWW) by default, this is dangerous for mutating data!
- Implements vector clocks, which makes updating data easier by making full custom merge functions easier to
write
- Implements Commutative Replicated Data Types - CRDTs, allowing fully automatic merging for certain data types with limited operations
- Also runs large systems in production, is commercially supported by Basho

### Commutative Replicated Data Types (CRDT)

- CRDTs are data types for which automated merging of concurrent updates is always possible in a safe manner
- Thus for CRDT datatypes it is safe to do updates even when network connections between database replicas are down
- When network connectivity resumes, the database can automatically do the data merging for CRDTs without any data loss
- Note, however, that updates are not immediately visible under network outage but will only become visible when network connectivity is resumed
- Using CRDTs provides strong eventual consistency and using it in in some applications a CP datastore can be replaced by an AP datastore
- High level intuition behind CRDTs: If the merged state of the data can be computed by performing (merging) all the operations made by the servers in any order, then the datatype is a CRDT
- Consider an integer counter i with initial value 0 that can only be incremented: If server x does an increment, server y does an increment, and server z does an increment, then final value of i is 3 irregardless of the order the increment updates to the database are deployed
- Thus integer counter with increment operation can be implemented as a CRDT

### Merging counters - State based CRDT

- The merge can be implemented by each one of the servers doing their local counts, and then broadcasting their latest local counter value. Thus each server keeps triplet (ix , iy , iz ) of counters, and updates each of the counters as the largest values the counters broadcasted so far
- When a database client asks for the value of i, these counters are summed up to provide the latest known
estimate of i
- This state based CRDT implementation can batch counter updates locally, and use a gossip based algorithm to update the counters to maximum value heard from each server in a best-effort manner

### Merging counters - Operation based CRDT

- Alternatively, each server could just broadcast all of the operations it does locally to all other replicas in a reliable manner, and each replica could then apply them in arbitrary order
- This requires that operations are not dropped or duplicated when transmitted to the other replicas, otherwise the counts will not match!
- The operation based CRDTs require reliable communications, but can be more efficient when the amount of data needed to send over the network in a state based CRDT is too large

### Positive / Negative Counter CRDT

- What if we want to allow decrement operations in addition to increment operations?
- We can implement this by having one CRDT counting the number of increments, and another counting the number of decrements
- The final value is then the increment counter value minus the decrement counter value
- Thus Positive / Negative counter can also be implemented as a CRDT



















