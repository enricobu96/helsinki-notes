---
attachments: [Clipboard_2021-10-05-10-18-08.png, Clipboard_2021-10-05-11-06-29.png, Clipboard_2021-10-05-11-09-31.png, Clipboard_2021-10-05-11-32-07.png, Clipboard_2021-10-05-11-32-37.png]
tags: [Big Data Platforms]
title: Lesson 7 - 05/10
created: '2021-10-05T07:16:02.479Z'
modified: '2021-10-07T09:17:00.380Z'
---

# Lesson 7 - 05/10

## NoSQL Databases (Cloud Datastores)

- Quite often the term Cloud datastore is used for database systems developed for the cloud, as they often do not fully support all features of traditional relational databases (RDBMS)
- Other term used often is NoSQL databases, as the original systems did not support SQL. However, some SQL
support is getting added also to cloud datastores (so the term is getting outdated quite fast)
- The cloud datastores can be grouped by many characteristics

### Scalable Cloud Data Store Features

Some of the key features many of these new datastores include (no single system contains all of these)?
- Ability to horizontally scale "simple operation" throughput over many servers
- Ability to automatically replicate and to distribute (partition/shared) data over many servers
- A simple call level interface or protocol (vs SQL)
- Weaker concurrency model than the ACID transactions of most relational (SQL) database systems
- Efficient use of distributed indexes and RAM for data storage
- Ability to dynamically add new attributes to data records < - no fixed data schema

### Grouping of Data Stores

#### Key-value stores

- E.g. Redis, Riak, Apache Cassandra, Scalaris
- A unique PK is used to access a data item that is usually a binary blob, but some systems also support more structured data
- Quite often use p2p technology such as distributed hash table (DHT) and consistent hashing to shared data and allow elastic addition and removal of servers
- Some systems use only RAM to store data, others also persist data to disk and can be used as persistend db replacements
- Most systems are AP systems but some support local row level transactions
- Cassandra is hard to categorize: it uses DHT, is an AP system, but has a very rich data model

#### Document stores

- E.g. Amazon SimpleDB, CouchDB, MongoDB
- For storing structured documents (e.g. XML)
- Do not usually support transactions or ACID semantics
- Usually allow very flexible indexing by many document fields
- Main focus on programmer productivity, not ultimate data store scalability

#### Extensible Record Stores

- E.g. Google BigTable, Google Megastore, Apache HBase, Hypertable, Apache Cassandra (still, partially)
- Google BigTable paper gave a new database design approach that the other systems have emulated
- BigTable is based on a write optimized design: read performance is sacrificed to obtain more write performance
- Other notable features: consistend and partition tolerant (CP) design, automaic sharding on PK, and a flexible data model

#### Scalable Relational Systems

- E.g. MySQL Cluster, VoltDB, Oracle Real Application Clusters (RAC)
- Data shared over a number of database servers
- Usually automatic replication of data to several servers supported
- Usually SQL database access + support for full ACID transactions
- For scalability joins that span multible database servers or global transactions should not be used by applications
- Scalability to very large (100+) database servers not demonstrated yet but should be done

### Eventual Consistency / BASE

- The term “Eventually Consistent” was popularized by the authors of Amazon Dynamo, which is a datastore that is an AP system - accessible and partition tolerant
- Also the term BASE (basically available, soft state, eventually consistent) is a synonym for the same approach
- Basically these are datastores that value accessibility over data consistency
- Quite often they offer support to automatically resolve some of the inconsistencies using e.g., version numbering or CRDTs - Commutative Replicated Data Types
- Example systems: Amazon Dynamo, Riak, Apache Cassandra

### Pro and Cons to RDBMS

#### RDBMS Supporter View

- RDBMS can do everything the scalable cloud data stores can do with similar scalability when used properly
- SQL is a convenient expressive declarative query language
- RDBMS have 30 years of engineering experience put into them and are highly tuned
- There are a very large number of specialized RDBMS for various application domains (interactive vs. analytics, RAM vs. disk based data, etc.)
- A standardization around relational schema and SQL brings benefits in design and training, where same set of skills can be effectively employed with another RDBMS system

#### RDBMS Opponent View

- The RDBMS vendors have not demonstrated scalability matching that of the newly architected scalable cloud data stores (e.g., BigTable)
- Primary key lookup is more easy to understand than SQL, and thus enables a much lower learning curve
- RDBMS force data schema on applications unnecessarily
- SQL makes it “too easy” to write expensive queries by accident such as complicated joins involving many tables and several servers. If these expensive operations are removed from the query language, the  complexity of a query evaluation becomes obvious to the programmer
- RDBMS systems have become dinosaurs in their 30 year rule of the database market, and the (hardware) assumptions on which they have been built are obsolete

### Scalable Data Stores - Future Speculation

- Long running serializable global transactions are very hard to implement efficiently, for scalability they sould be avoided at all costs. Counterexamples: Google Percolator, Google Cloud Spanner
- The requirement of low latency and hidh availability make AP solutions attractive but they are more difficult to use for the programmer than CP systems
- The time of "one size fits all", where a RDBMS was a solution to all datastore problems has passed, and scalable cloud data stores are here to stay
- ACID transactions are needed for crucial things e.g. financial transactions
- Many of the new systems are not yet proven in production
- There will be a consolidation to a smaller number of data stores, once the “design space exploration” settles down

### NewSQL - Google Cloud Spanner

- A beta release of Google’s internal Spanner Database
- SQL support
- ACID transactions that can span multiple servers globally
- Fully consistent database with a single global database image
- Implementation based on Paxos for replication, Transaction commit priority made using physical timestamps
- All database server clocks synchronized very tightly using atomic clocks + GPS based time synchronization
- All database transactions have to wait two times the max clock drift holding write locks before committing a transaction
- Open source alternatives being developed: CockroachDB, Apache Kudu

## Probabilistic Datastructures

- RAM is very expensive than HDDs and SSDs, and is much faster
- Probailistic datastructures allow much more efficient RAM usage at the expense of some inaccuracy in the results
- Bloom filters are an example of a probabilistic datastructure that is heavily used in several NoSQL databases to minimize I/O using a small RAM based probabilistic index
- They can be used also for many data analytics tasks to do approximate computations

### Example: Bloom filter for Web page caching

- Problem: We are designing a caching mechanism for a Web server. We are given a stream of Web page URLs,
listing each URL that is being accessed
- We want to find those Web page URLs that are being accessed more than once to cache them
- We do not want to cache any Web pages only accessed once, as this can potentially remove more frequently accessed data from the cache
- We allow for a small number of false positives: It is OK to cache a small percentage of items on first access if that speeds up the algorithm and especially if it lowers the memory requirements needed

#### What would you do?

- Traditional solution: Use a hash table for storing each one of the encountered URLs, cache each URL when it is encountered the second time
  - Simple solution but requires potentially a lot of memory to store the hashed URLs
- Second traditional design: Use an external database to store all encountered URLs
  - Scales beyond main memory hash table but is potentially slow as each cache access needs a database query
- Third design: Use a Bloom filter to record the set of encountered URLs

#### So... Bloom Filters

Highly memory-efficient probabilistic data structure to store sets

![](@attachment/Clipboard_2021-10-05-11-06-29.png)

##### Bloom Filter Lookup

![](@attachment/Clipboard_2021-10-05-11-09-31.png)

##### Avoiding false positives
- Increasing Bloom filter size decreases the number of false positives. However, Bloom filters are usually used when memory needs to be saved
- A too small a k, for example k = 1, suffers from fairly frequent hash collisions (see: Birthday paradox), thus avoiding k = 1 should be done if possible
- However, if k is too large, the Bloom filter quickly fills with bits set to one, as k indexes are assigned to one on for each inserted data item
- The optimal number k depends thus on both the memory m available and the number of items n to be inserted to the Bloom filter
- Very large k also slows processing, as each lookup of a bit in Bloom filter is a random memory access

##### Bloom Filter False Positives

![](@attachment/Clipboard_2021-10-05-11-32-07.png)

##### Bloom Filter Parameters

![](@attachment/Clipboard_2021-10-05-11-32-37.png)

##### Traditional Hash Table Memory Usage

- Assume that in our Web page caching example the average length of a URL is 25 bytes, and a worst-case scenario that each one of the URLs is unique
- Then the amount of memory to store the URL strings in a hash table is 25 bytes ·10000000 ≈ 238 megabytes
- Thus using a Bloom filter and allowing 0.8% false positive rate in caching decisions has reduced the memory requirements by at least 238 − 12 = 226 megabytes

##### Pros and Cons

###### Pros

- Bloom filters are a memory efficient probabilistic data structure for storing sets
- Very simple implementation, very fast for small number of hash functions
- Can be combined with a traditional database index: If Bloom filter says a data item is not in a database, a traditional index need not be traversed. If Bloom filter says “maybe”, traditional index (that may be on a hard disk) needs be consulted
- Bloom filters allow for efficient parallelization to create them: Just take the bitwise or of the Bloom filters created in parallel for subsets of the data
- Many variants exist, see for example stable Bloom filters by Deng for stream processing, which start forgetting older items in a data stream in probabilistic fashion

###### Cons

- No delete operation available in basic version
- Need to tune k based on data volume n
- To get a very small false positive probability a large number of hash functions need to be used, which makes very precise Bloom filters slow
- Large Bloom filters are not cache friendly
- If exposed to user generated data, may need (very slow) cryptographic hash functions to avoid collisions made on purpose
- Computing a large number of hash functions can be expensive
- There are even more memory efficient data structures allowing deletions, see e.g., Cuckoo Filters by Fan et al.


















