---
attachments: [Clipboard_2021-11-26-12-24-32.png, Clipboard_2021-11-26-12-32-11.png, Clipboard_2021-11-26-12-41-12.png, Clipboard_2021-11-26-12-42-38.png, Clipboard_2021-11-26-12-43-53.png, Clipboard_2021-11-26-12-44-13.png, Clipboard_2021-11-26-12-48-07.png, Clipboard_2021-11-26-12-49-21.png, Clipboard_2021-11-26-13-03-36.png, Clipboard_2021-11-26-13-05-01.png, Clipboard_2021-11-26-13-06-19.png, Clipboard_2021-11-26-13-26-40.png, Clipboard_2021-11-26-13-27-42.png, Clipboard_2021-11-26-13-29-20.png, Clipboard_2021-11-26-13-29-48.png, Clipboard_2021-11-26-13-32-16.png, Clipboard_2021-11-26-13-32-38.png, Clipboard_2021-11-26-13-32-54.png, Clipboard_2021-11-26-13-36-04.png, Clipboard_2021-11-26-13-37-10.png, Clipboard_2021-11-26-13-38-57.png, Clipboard_2021-11-26-13-39-11.png]
tags: [Human Computer Interaction]
title: Lesson 8 - 26/11
created: '2021-11-26T10:18:22.956Z'
modified: '2021-11-26T11:52:48.692Z'
---

# Lesson 8 - 26/11

## AR and VR

![](@attachment/Clipboard_2021-11-26-12-24-32.png)

### Augmented reality (AR)

- Must mix real and virtual
- Registered in 3D with physical world
- Interactive in real time

**Why?**:
- Enables providing augmented information and guidance in the physical context
- Enables investigating virtual 3D models in physical environment

A lot of applications:
![](@attachment/Clipboard_2021-11-26-12-32-11.png)

### Virtual reality

- Virtual world
- Immersion
- Sensory feedback
- Interaction

**Why?**:
- Utilisation of immersion
- Simulation of real-world situations
- Designing beyond the physical world
- Remote collaboration

Immersive analytics:
- Supporting for collaboration
- Allow users to immerse themselves in their data
- Large touch surfaces in addition to AR and VR

### Interaction

**Interaction technique**: the fusion of input and output, consisting of all sw and hw elements, that provides a way for the user to accomplish a task.

![](@attachment/Clipboard_2021-11-26-12-41-12.png)

Requirements for interaction techniques in AR and VR:
- 6 degrees of freedon
- Ability to interact in 3D physical space
- Ability to interact with 2D or 3D virtual information

#### Tracking

![](@attachment/Clipboard_2021-11-26-12-42-38.png)

Active tracking:
![](@attachment/Clipboard_2021-11-26-12-43-53.png)

Passive tracking:
![](@attachment/Clipboard_2021-11-26-12-44-13.png)

### Characterization of input techniques

- Performance: speed and time
- Expressiveness: Deegrees Of Freedom
- Comfort
- Learnability
- Memorability

![](@attachment/Clipboard_2021-11-26-12-48-07.png)

#### Haptics

![](@attachment/Clipboard_2021-11-26-12-49-21.png)

**Devices**:
- Multitouch: people have used them BUT less DOF
- Hand-held controllers: reliables, many DOF BUT external devices are needed and cannot use hands for other tasks
- Pen/stylus: precise pointing and drawing, enables direct manipulation BUT need for holding something in a hand and no tactile feedback when used in mid-air
- Data gloves: many possible inputs, more reliable than gestural interfaces BUT difficult to wear, different hand sizes, not very mobile atm (so not feasible for AR)
- Hand gestures: no external devices needed BUT recognition rate not 100%, hand fatigue, lack of tactile feedback
- Tangible interaction: tactile feedback, more natural interaction BUT difficult to modify physical objects and interaction limited to 2D if used on a table
- Head movements: stable and hands free BUT midal-touch problem, ergonomics
- Foot movements: hands-free BUT requires space around and limited fidelity

**Output**: used as a simple feedback (force feedback, vibrations)

#### Speech

- Speech: works well when giving explicit predetermined commands and hands-free BUT difficult of knowing what commands are possible, possible dialects, not usefult for continuous interaction such as drawing

**Output**:
![](@attachment/Clipboard_2021-11-26-13-03-36.png)

#### Vision

- Eye-movements: fast and ergonomic BUT accuracy is limited by the eye-tracking devices and involuntary selections, Midas touch problem

**Output**:
![](@attachment/Clipboard_2021-11-26-13-05-01.png)

**Depth perception**
![](@attachment/Clipboard_2021-11-26-13-06-19.png)

Monocular problems:
- Monocular depth cues
- Parallax problem
- Occlusion problem in AR

Binocular problems:
- Binocular disparity

Oculomotor problems:
- Accomodation/accomodation-convergence mismatch

### Display types

![](@attachment/Clipboard_2021-11-26-13-26-40.png)

![](@attachment/Clipboard_2021-11-26-13-27-42.png)

- Handheld displays
- Wearable AR displays
- Projectors

Future:
![](@attachment/Clipboard_2021-11-26-13-29-20.png)

### Multimodal interaction

![](@attachment/Clipboard_2021-11-26-13-29-48.png)

![](@attachment/Clipboard_2021-11-26-13-32-16.png)

Pinpointing: primary pointing + refinement

![](@attachment/Clipboard_2021-11-26-13-32-38.png)

![](@attachment/Clipboard_2021-11-26-13-32-54.png)

### Types of attention

![](@attachment/Clipboard_2021-11-26-13-37-10.png)

#### Multiple resources theory

![](@attachment/Clipboard_2021-11-26-13-38-57.png)

![](@attachment/Clipboard_2021-11-26-13-39-11.png)
