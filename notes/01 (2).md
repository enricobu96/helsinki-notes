---
attachments: [Clipboard_2022-01-18-12-37-53.png, Clipboard_2022-01-18-12-45-38.png, Clipboard_2022-01-18-12-46-09.png, Clipboard_2022-01-18-12-46-33.png, Clipboard_2022-01-18-12-53-08.png, Clipboard_2022-01-18-12-57-21.png, Clipboard_2022-01-18-13-01-05.png, Clipboard_2022-01-18-13-11-41.png, Clipboard_2022-01-18-13-21-43.png, Clipboard_2022-01-18-13-22-49.png, Clipboard_2022-01-18-13-23-20.png, Clipboard_2022-01-18-13-23-34.png, Clipboard_2022-01-18-13-24-29.png, Clipboard_2022-01-18-13-25-26.png, Clipboard_2022-01-18-13-25-42.png, Clipboard_2022-01-18-13-26-31.png, Clipboard_2022-01-18-13-27-57.png, Clipboard_2022-01-18-13-28-18.png, Clipboard_2022-01-18-13-29-44.png, Clipboard_2022-01-18-13-34-29.png, Clipboard_2022-01-18-13-36-42.png, Clipboard_2022-01-18-13-37-59.png, Clipboard_2022-01-18-13-38-19.png, Clipboard_2022-01-18-13-38-36.png, Clipboard_2022-01-18-15-21-18.png, Clipboard_2022-01-18-15-24-12.png]
tags: [Information Retrieval]
title: Lesson 1 - 18/01
created: '2022-01-18T10:13:25.441Z'
modified: '2022-01-18T13:26:59.502Z'
---

# Lesson 1 - 18/01

## Introduction

![](@attachment/Clipboard_2022-01-18-12-37-53.png)

IR is the study of systems that manage information items with the aim of helping users satisfy information needs; therefore it deals with the way information items should be represented, stored and retrieved

Challenges:
- Information can be hard to specify
  - Ambiguity of language: language is generative and broad
  - Synonymy: the same main content word to describe a subject is only ~10-20%
- Relevance is largely subjective; e.g. Micheal Jordan - River Jordan
- Enormous amounts of data/information involved ![](@attachment/Clipboard_2022-01-18-12-46-33.png)

**Relevance** can be defined as follows: a document is relevant if it contains knowledge that helps the user to resolve their information need. This definition implies answers do not need not contain all the required information (a document that helps is also relevant)

### Search process as viewed by an IR researcher

![](@attachment/Clipboard_2022-01-18-12-46-09.png)

### Different "flavors" of IR systems

- Web search
- Site-based searching, e.g. wikipedia.org
- File System search, e.g. Spotlight
- Searching with intermediaries, e.g. call center that have to check sth on the database (-> should know how to translate request into query)

### Desirable characteristics of IR systems

- Robust in the face of rich and complex data -> poor autorship, malformed HTML, binary data, multiple files formats...
- Tolerant of searcher input error -> queries by most users are fairly primitive, contain spelling errors
- Able to produce useful output

#### Measuring performance

- Efficiency: fastness, resources...
- Quality of answers

#### IR effectiveness

An IR is **effective** if it is good at finding relevant documents in response to queries. It is relative: some queries are dissicult to resolve, others may have many relevan documntes.

**Measuring**: many methods

![](@attachment/Clipboard_2022-01-18-12-53-08.png)

!!! we don't always know _#relevant docs_

## Unstructured data in 1650 (?)

![](@attachment/Clipboard_2022-01-18-12-57-21.png)

BUT grep is not a good solution:
- Really slow for large collections, and need to scan every document in full
- Not-calpurnia is non-trivial
- Other operations (e.g. find the word "romans" near "countryman") not necessary feasible

### -> Term-document incidence matrix

![](@attachment/Clipboard_2022-01-18-13-01-05.png)

To answer the query `brutus and ceasar and not calpurnia`:
1. Take the vectors for `brutus`, `ceasar` and `calpurnia`
2. Complement the vector of `calpurnia`
3. Do a bitwise AND on the three vectors: 110100 AND 110111 AND 101111 = 100100

## Inverted index

Say N=10^7 documents, each with 1000 words. On average 6 bytes per word -> 60 GB. Assume there are M = 500000 distinct terms in the collection.
Now we can't build the incidence matrix: we have 5 trillion 0s and 1s (matrix with 500k rows and 1E7 columns) BUT the matrix has no more than 10 billion 1s: the matrix is extremely sparse (mostly 0s).

![](@attachment/Clipboard_2022-01-18-13-11-41.png)

How to:

![](@attachment/Clipboard_2022-01-18-13-21-43.png)

Tokenization and preprocessing:
![](@attachment/Clipboard_2022-01-18-13-22-49.png)

Generate postings:
![](@attachment/Clipboard_2022-01-18-13-23-20.png)

Sort postings:
![](@attachment/Clipboard_2022-01-18-13-23-34.png)

Create lists, count document frequency:
![](@attachment/Clipboard_2022-01-18-13-24-29.png)

Finally:
![](@attachment/Clipboard_2022-01-18-13-25-26.png)
![](@attachment/Clipboard_2022-01-18-13-25-42.png)

### Processing boolean queries

![](@attachment/Clipboard_2022-01-18-13-26-31.png)

![](@attachment/Clipboard_2022-01-18-13-27-57.png)

And we advance one of the pointers:
![](@attachment/Clipboard_2022-01-18-13-28-18.png)

- This procedure is linear in the length of the posting lists: O(p+q)
- This only works if postings lists are sorted

![](@attachment/Clipboard_2022-01-18-13-29-44.png)

## Boolean queries

- The boolean retrieval model can answer any query that is a boolean expression
- Primary commercial retrieval tool for 3 decades
- Still used somehow, e.g. Google lets you use boolean operators

### Query optimization

![](@attachment/Clipboard_2022-01-18-13-34-29.png)

## Lexicon

- The data structure for storing the term vocabulary (i.e. the data, i.e. the words)
- For each term t we need to store a couple of items:
  - Document frequency
  - Pointer to postings list for t

### Fast lexicons

![](@attachment/Clipboard_2022-01-18-13-36-42.png)

#### Hash table

![](@attachment/Clipboard_2022-01-18-13-37-59.png)

![](@attachment/Clipboard_2022-01-18-13-38-19.png)

**Collisions**:

![](@attachment/Clipboard_2022-01-18-13-38-36.png)
- Chaining (same as usual)
- Linear probing:
  ![](@attachment/Clipboard_2022-01-18-15-21-18.png)
- Perfect hashing: hash function that has no collisions. Works only for a specific set of terms, which must be given in advance; takes some time to construct and has to be reconstructed is set changes

#### Tries

Tree structure that stores a set of strings

![](@attachment/Clipboard_2022-01-18-15-24-12.png)

**Lookup**: we try to match each successive character of the string to an edge label in the trie, starting from the root.

- As we walk down the trie during a lookup, at each node we encounter we need to make a decision about which outgoing branch to follow: this leads to a space-time trade-off
- Support prefix matching much more naturally than hash tables -> useful for query suggestions/autocompletion
- No need to reahash but careful implementation needed to keep space usage down: a key design decision is how to implement the search structure at each node
