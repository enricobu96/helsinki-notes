---
attachments: [Clipboard_2022-01-18-16-53-22.png, Clipboard_2022-01-18-16-55-39.png, Clipboard_2022-01-18-16-58-08.png, Clipboard_2022-01-18-17-26-45.png, Clipboard_2022-01-19-16-57-17.png, Clipboard_2022-01-19-17-05-43.png, Clipboard_2022-01-19-17-07-16.png, Clipboard_2022-01-19-17-08-51.png, Clipboard_2022-01-19-17-11-10.png, Clipboard_2022-01-19-17-11-33.png, Clipboard_2022-01-19-17-13-23.png]
tags: [Probabilistic Graphical Models]
title: Lesson 1 - 18/01
created: '2022-01-18T14:16:42.783Z'
modified: '2022-01-19T15:13:26.550Z'
---

# Lesson 1 - 18/01

## Motivation and justification

Historical introduction

![](@attachment/Clipboard_2022-01-18-16-53-22.png)

## Deductive logic

McCarthy'l system

![](@attachment/Clipboard_2022-01-18-16-55-39.png)

But it has some limits:
- Qualification problem: impossible to list every thing to take into account
  e.g. ![](@attachment/Clipboard_2022-01-18-16-58-08.png)
- Monotonicity of logic: if D implies a, then D and sth_else also logically imply a -> it does not allow us to change our minds

## Monty hall example

Yaaaaay love it

## Probability

### Frequentists vs Bayesians

![](@attachment/Clipboard_2022-01-18-17-26-45.png)

### Connection to Decision Theory

![](@attachment/Clipboard_2022-01-19-16-57-17.png)

## Theoretical arguments

### Cox's theorem

Any good calculus of plausability of statements should meet the following requirements:
- Divisibility and comparability: the plausability of a statement is a real number and is dependent on information we have related to the statement
- Common sense: aristotelian deductive logic should be the special case of reasoning only with statements known to be true (or false), and plausibilities should vary smoothly with the assessments of plausabilitities of inputs
- Consistency: if the plausibility of a statement can be derived in two ways, the two results must be equal

-> Probability calculus meets these requirements

## Probabilistic Graphical Models

**How can we represent the probabilities?**
A Bayesian network consists of two components:

![](@attachment/Clipboard_2022-01-19-17-05-43.png)

(DAG = directed acyclic graph)

Example: ![](@attachment/Clipboard_2022-01-19-17-08-51.png)

**How can we efficiently compute desired quantities?**
Belief propagation (Pearl, 1986) for performing efficient inference in Bayesian networks with polytree/singly connected structures; Junction Tree algorithm (Lauritzen and Speigelhalter, 1988) for arbitrary structures.

![](@attachment/Clipboard_2022-01-19-17-07-16.png)

### Importatant characteristics of Bayesian Networks

- Guaranteed to define a unique probability distribution over the network variables: building a Bayesian network, we specify a probability for every proposition that can be expressed using these network variables (see example above)
- Modular: considers only variables and their direct parents (e.g. causes) ad a time
- Compact: allows one to specify an exponential sized probability distribution using a polynomial number of probabilities

## Some working examples

**Guinea Pigs**: ![](@attachment/Clipboard_2022-01-19-17-11-10.png)

**The ALARM Network**: ![](@attachment/Clipboard_2022-01-19-17-11-33.png)

And a lot more, like:
- Biology
- Spam filtering
- Speech recognition (-> hidden Markov models)
- Natural language processing

## Conclusions

![](@attachment/Clipboard_2022-01-19-17-13-23.png)
